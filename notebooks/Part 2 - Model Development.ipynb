{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "# Part 2 - Model Development\n# Modeling Using IBM Debater\u00ae Thematic Clustering of Sentences\n\n### Table of Contents\n\n* [0. Prerequisite](#prerequisite)\n* [1. Modeling](#1)   \n* [2. Testing](#2)\n* [3. Example](#3)\n* [Authors](#authors)\n\n<a class=\"anchor\" id=\"prerequisite\"></a>\n### 0. Prerequisites\n\nBefore you run this notebook complete the following steps:\n- Insert a project token\n- Import required modules\n\n#### Insert a project token\n\nWhen you import this project from the Watson Studio Gallery, a token should be automatically generated and inserted at the top of this notebook as a code cell such as the one below:\n\n```python\n# @hidden_cell\n# The project token is an authorization token that is used to access project resources like data sources, connections, and used by platform APIs.\nfrom project_lib import Project\nproject = Project(project_id='YOUR_PROJECT_ID', project_access_token='YOUR_PROJECT_TOKEN')\npc = project.project_context\n```\n\nIf you do not see the cell above, follow these steps to enable the notebook to access the dataset from the project's resources:\n\n* Click on `More -> Insert project token` in the top-right menu section\n\n![ws-project.mov](https://media.giphy.com/media/jSVxX2spqwWF9unYrs/giphy.gif)\n\n* This should insert a cell at the top of this notebook similar to the example given above.\n\n  > If an error is displayed indicating that no project token is defined, follow [these instructions](https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/token.html?audience=wdp&context=data).\n\n* Run the newly inserted cell before proceeding with the notebook execution below\n\n#### Import required modules\n\nImport and configure the required modules.\n\n###  1. Modeling <a class=\"anchor\" id=\"1\"></a>\n\nNow that we have processed data to test the model, \nin this section, we will create the clustering model. We will:\n1. Create a TF-IDF matrix using the input text. You will notice that in [TfidfVectorizer](!https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) there are parameters:\n    * max_df=0.75 means that all terms in more than 75% of documents will be ignored\n    * min_df=0.1 means that all terms in less than 10% of documents will be ignored\n    * stop_words='english' means Sklearn's stop words are removed from the input data\n    * ngram_range = (1,3) means that unigrams, bigrams, and trigrams are used\n2. Then this matrix is used in a KMeans model.\n    * Number of clusters is input.\n    * If no number of clusters is input then we determine the best number of clusters using [silhouette scores](!https://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_score.html)\n3. Additionally, a function is written to extract the top terms used to cluster the text.\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "def get_top_n_terms_per_cluster(km_model, terms, n=5):\n    \"\"\"\n    Gets the top terms used to cluster text\n    \n    :param km_model: KMeans model\n    :param terms: list of terms from a TfidfVecotrizer object\n    :return: dictionary mapping cluster number to top n terms\n             {cluster_number: [term1, term2,..., termn]}\n    \"\"\"\n    cluster_terms = defaultdict(list)\n    \n    order_centroids = km_model.cluster_centers_.argsort()[:, ::-1]\n    for i in range(len(order_centroids)):\n        cluster = order_centroids[i]\n        for term_idx in cluster[:n]:\n            cluster_terms[i].append(terms[term_idx])\n            \n    return cluster_terms"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "def run_kmeans(number_of_clusters, tfidf_matrix):\n    \"\"\"\n    :param number_of_clusters: int\n    :param tfidf_matrix: matrix from TfidfVectorizer object\n    :return: KMeans model, list of cluster labels\n    \"\"\"\n    km_model = KMeans(n_clusters=number_of_clusters, init='k-means++')\n    km_model.fit(tfidf_matrix.toarray())\n    clusters = km_model.labels_.tolist()\n    return km_model, clusters"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "def run_model(X, number_of_clusters=None, number_of_terms=5, max_number_of_groups=5):\n    \"\"\"\n    Runs the entire modeling process\n    1. create TFIDF matrix\n    2. run KMeans with TFIDF matrix\n    3. get top terms used\n    \n    :return: (list of cluster assignments, \n              dictionary mapping cluster number of terms)\n    \"\"\"\n    # First find TFIDF matrix\n    tfidf_vectorizer = TfidfVectorizer(max_df=0.75 if len(X)>1 else 1, \n                                       min_df=0.1 if len(X)>1 else 1,\n                                       stop_words='english',\n                                       use_idf=True, \n                                       ngram_range=(1,3),\n                                      )\n\n    tfidf_matrix = tfidf_vectorizer.fit_transform(X)\n    terms = tfidf_vectorizer.get_feature_names()\n    \n    # Number of clusters must be > 2 for silhouette_score to work.\n    # If there are 2 or less comments, then just set to number of comments.\n    number_of_clusters = len(X) if len(X) <= 2 else number_of_clusters\n    \n    if number_of_clusters:\n        # If there's a specific number of clusters specified, then run with that number.\n        km_model, best_clusters = run_kmeans(number_of_clusters, tfidf_matrix)\n        cluster_terms = get_top_n_terms_per_cluster(km_model, terms, number_of_terms)\n    else:\n        # Automatically find number of clusters with silhouette_score\n        # but have a maximum of max_number_of_groups \n        max_silhouette_score = 0\n        for k in range(2, min(max_number_of_groups, len(X))):\n            km_model, clusters = run_kmeans(k, tfidf_matrix)\n            current_silhouette_score = silhouette_score(tfidf_matrix, clusters)\n            if current_silhouette_score > max_silhouette_score:\n                max_silhouette_score = current_silhouette_score\n                cluster_terms = get_top_n_terms_per_cluster(km_model, terms, number_of_terms)\n                best_clusters = clusters\n            \n    return best_clusters, cluster_terms"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### 2. Testing Model  <a class=\"anchor\" id=\"2\"></a>"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Next, we can test the clustering model with the dataset we downloaded and preprocessed in sections 1.1 and 1.2. We evaluate the model using [V-measure](!https://scikit-learn.org/stable/modules/generated/sklearn.metrics.v_measure_score.html), which is the harmonic mean between [homogeneity](!https://scikit-learn.org/stable/modules/generated/sklearn.metrics.homogeneity_score.html#sklearn.metrics.homogeneity_score) and [completedness](!https://scikit-learn.org/stable/modules/generated/sklearn.metrics.completeness_score.html#sklearn.metrics.completeness_score). The higher the number, the better the model is, values are between 0 and 1.\n\nAdditionally, we create a baseline model that predicts random clusters for each input. We want our clustering model defined in 1.3 to do better than this baseline."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "def run_model_testing(list_of_groups, df, test_size=50):\n    average_homogeneity_score, average_completeness, average_v_measure = 0, 0, 0\n    avg_baseline_score = 0\n\n    for group in list_of_groups[:test_size]:\n        X_test = list(df[df.label_id.isin(list(group))].Sentence.values)\n        y_test = list(df[df.label_id.isin(list(group))].label_id.values)\n        n = len(df[df.label_id.isin(list(group))].label_id.unique())\n        \n        clusters, cluster_terms = run_model(X_test)\n        \n        average_homogeneity_score += homogeneity_score(y_test, clusters)\n        average_completeness += completeness_score(y_test, clusters)\n        average_v_measure += v_measure_score(y_test, clusters)\n        \n        # baseline\n        baseline_predictions = np.random.choice(np.arange(1, 5), len(X_test))\n        avg_baseline_score += v_measure_score(y_test, baseline_predictions)\n\n    \n    print('Test V Measure:     ', average_v_measure/ test_size)\n    print('Baseline V Measure: ', avg_baseline_score / test_size)\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "We see that our model actually does do much better than randomly picking clusters."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "run_model_testing(list_of_groups, df)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### 3. Example  <a class=\"anchor\" id=\"3\"></a>\nFinally, we use a sample of comments a retail company could see and run the model on it."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "comments_5 = [\n    'Customer service was polite.',\n    'The socks are a pretty color but expensive.',\n    'The shirt I bought was green and service was great.',\n    'I think the sweater and socks were perfect.',\n    'I do not like the shoes, so ugly and expensive.',\n]\n\ncomments_20 = [\n    'Out of all the products I bought, the shirt was my favorite because it is comfortable. However, the sweater and socks really missed the mark and were not worth it.',\n    'My order arrived several days late. But when I contacted customer service they were very helpful and refunded me.',\n    'Horrible customer service, I have never met such rude people. Would not recommend at all.',\n    'Everything I ordered arrived perfectly on time and looked exactly like in the pictures! This company has high quality products.',\n    'The company is okay.',\n    'Prices are ridiculous',\n    'Way too overpriced.',\n    'Can never find anything that fits right',\n    'Nice clothes for your teenager.',\n    'They were really well organized and made the experience way less stressful than i thought it would be',\n    'Friendly staff, good range of clothes.',\n    'Fashionable place',\n    'Decent quality product! Friendly customer service',\n    'I really love all the clothes, beautiful. Just a little too expensive',\n    'Great quality of the items, cashier and stocker were very friendly.',\n    'Ugly and overpriced.'\n    'This place was okay and I did find a couple plain shirts for cheap. Overall disappointed with their selection of basics and prices.',\n    'Rude employees. Horrible customer service and limited clothing. Only good thing is cheap clothing',\n    'Service was good and I got a lot for my money',\n    'My favorite brand',\n]"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "def print_clustering_result(sentences, labels, top_terms):\n    label_to_sentences = defaultdict(list)\n    for i in range(len(labels)):\n        label_to_sentences[labels[i]].append(sentences[i])\n    \n    number_of_groups = len(label_to_sentences.keys())\n    for i in range(number_of_groups):\n        print('---------------------------------------')\n        print('Group {}. Top Terms: {}'.format(i, top_terms[i]))\n        for j in range(len(label_to_sentences[i])):\n            print('- ' + label_to_sentences[i][j])"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Automatically determine number of clusters.\n# However can also add the parameter e.g. number_of_clusters=5\nfor comments in [comments_5, comments_20]:\n    best_labels, top_terms = run_model(comments)\n    print_clustering_result(comments, best_labels, top_terms)\n    print('\\n\\n')"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Authors\nThis notebook was created by the [Center for Open-Source Data & AI Technologies](http://codait.org).\n\nCopyright \u00a9 2020 IBM. This notebook and its source code are released under the terms of the MIT License."
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<div style=\"background:#F5F7FA; height:110px; padding: 2em; font-size:14px;\">\n<span style=\"font-size:18px;color:#152935;\">Love this notebook? </span>\n<span style=\"font-size:15px;color:#152935;float:right;margin-right:40px;\">Don't have an account yet?</span><br>\n<span style=\"color:#5A6872;\">Share it with your colleagues and help them discover the power of Watson Studio!</span>\n<span style=\"border: 1px solid #3d70b2;padding:8px;float:right;margin-right:40px; color:#3d70b2;\"><a href=\"https://ibm.co/wsnotebooks\" target=\"_blank\" style=\"color: #3d70b2;text-decoration: none;\">Sign Up</a></span><br>\n</div>"
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.7",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.7.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}